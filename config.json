{
  "model_config": {
    "vocab_size": 256,
    "block_size": 256,
    "n_head": 4,
    "d_model": 128,
    "dropout": 0.1,
    "max_pos": 4096,
    "sliding_window": 256,
    "attention_sink": 4,
    "n_kv_head": null,
    "n_layer": 2
  },
  "training_config": {
    "batch_size": 8,
    "learning_rate": 3e-4,
    "weight_decay": 0.1,
    "grad_clip": 1.0,
    "max_iters": 5000,
    "eval_interval": 500,
    "eval_iters": 200,
    "warmup_iters": 500,
    "lr_decay_iters": 5000,
    "min_lr": 3e-5,
    "device": "cuda",
    "compile": false
  },
  "generation_config": {
    "max_new_tokens": 100,
    "temperature": 0.5,
    "top_k": 10,
    "top_p": null,
    "eos_token": 1
  },
  "paths": {
    "model_save_path": "models/jithformer_checkpoint.pt",
    "dataset": "wikitext-2",
    "log_dir": "logs"
  }
}
